{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Define an input of 2 batch with 5 columns which be send through a linear layer in ANN which will output a 5x6 with Relu activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "inputs = torch.randn(2,5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "output= layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = output.mean(dim=1,keepdim=True)\n",
    "var = output.var(dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1324],\n",
       "        [0.2170]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0231],\n",
       "        [0.0398]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the formula for Layer Norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_norm = (output - mean)/ torch.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
       "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_norm.var(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9341e-09],\n",
       "        [0.0000e+00]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_norm.mean(dim=1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of the output norm was no exact to zero because of some error in calculation in python\n",
    "# so we set the printoptions so now we get the mean exact to zero\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0000],\n",
       "        [    0.0000]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_norm.mean(dim=1, keepdim=True)\n",
    "#As you can see we have success fully acheived a  layer norm functionality \n",
    "# with a standard deviation of 1 and a mean of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Layer Norm we achieved will help to resolve two issues while trainin:\n",
    "1. It will help to converge the training much more faster \n",
    "2. Instability in learning meaning can help in reduce the problem of vanishing as well as exploding gradients problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets code a Layer Norm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.eps = 1e-5\n",
    "        self.shift =  nn.Parameter(torch.zeros( embedding_dim))\n",
    "        self.scale = nn.Parameter(torch.ones(embedding_dim))\n",
    "        \n",
    "    def forward(self, y):\n",
    "        mean = y.mean(dim=1, keepdim=True)\n",
    "        var = y.var(dim=1, keepdim=True, unbiased= False)\n",
    "        \n",
    "        out_norm = (y - mean)/ torch.sqrt(var) + self.eps\n",
    "        \n",
    "        return self.scale * out_norm + self.shift \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We defined two more arguments shift , scale and eps(epsilon) \n",
    "Eps is a constant param which is used in a situation when the variance is 0 which leads to wrong normalization\n",
    "where as scale and shift is used at the time of training as they both have similar dimensions as input they both adjust at the time of training if doing so will lead to improve te models performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = inputs.shape[-1]\n",
    "# context_length = \n",
    "lay_n = LayerNorm(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_norm = lay_n(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0000],\n",
       "        [    0.0000]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_norm.mean(dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
